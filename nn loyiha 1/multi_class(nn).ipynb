{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qKZ2XIy0gIwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff596a4-c9a9-44a7-93f4-b5cca5a5f95c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "\u001b[1m2110848/2110848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n"
          ]
        }
      ],
      "source": [
        "#reutors datasetini yuklab olamiz\n",
        "from tensorflow.keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kerakli kutubxonalarni yuklash\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "ge5pI43igwc9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train va test datani qanchaligini korish\n",
        "len (train_data), len (test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmV9oAoFhBm8",
        "outputId": "b6470698-fe4e-448b-b183-fb9218c7f5d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8982, 2246)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numpy orqali umumiy ma'lumot olamiz\n",
        "import numpy as np\n",
        "def dataset_info (data,labels):\n",
        "  print(\"Dataset Information\")\n",
        "  print(\"-\" * 40)\n",
        "  print(f\"Num of samples{len(data)}\")\n",
        "  print(f\"Num of unique labels:{len(np.unique(labels))}\")\n",
        "  print(f\"First smaple (decoded) :{data[0]}\")\n",
        "  print(f\"First label:{labels[0]}\")\n",
        "  print(f\"Max sequence length: {max(len(sequence) for sequence in data )}\")\n",
        "  print(f\"Min sequence length: {min(len(sequence) for sequence in data)}\")\n",
        "  print(f\"Average sequence length: {np.mean([len(sequence) for sequence in data]):.2f}\")\n",
        "\n",
        "\n",
        "print(\"Training Data Info:\")\n",
        "dataset_info(train_data, train_labels)\n",
        "\n",
        "print(\"Testing Data Info:\")\n",
        "dataset_info(test_data, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy9ng35BhKQz",
        "outputId": "02dd65f5-c3e3-43dc-8114-92dd4cbbd0bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Info:\n",
            "Dataset Information\n",
            "----------------------------------------\n",
            "Num of samples8982\n",
            "Num of unique labels:46\n",
            "First smaple (decoded) :[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "First label:3\n",
            "Max sequence length: 2376\n",
            "Min sequence length: 13\n",
            "Average sequence length: 145.54\n",
            "Testing Data Info:\n",
            "Dataset Information\n",
            "----------------------------------------\n",
            "Num of samples2246\n",
            "Num of unique labels:46\n",
            "First smaple (decoded) :[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
            "First label:3\n",
            "Max sequence length: 1032\n",
            "Min sequence length: 2\n",
            "Average sequence length: 147.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decoding\n",
        "word_index = reuters.get_word_index()\n",
        "reserve_word_index = dict(\n",
        "    [(value, key) for (key, value) in word_index.items()])\n",
        "decoded_newswire = \" \".join(\n",
        "    [reserve_word_index.get(i - 3, \"?\") for i in train_data[5]])"
      ],
      "metadata": {
        "id": "v_sn1TIzkuJN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_newswire"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "5zSfJdlH1Etv",
        "outputId": "7b05f8e6-7ed3-4b18-c49c-01e0d8633925"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? the u s agriculture department estimated canada's 1986 87 wheat crop at 31 85 mln tonnes vs 31 85 mln tonnes last month it estimated 1985 86 output at 24 25 mln tonnes vs 24 25 mln last month canadian 1986 87 coarse grain production is projected at 27 62 mln tonnes vs 27 62 mln tonnes last month production in 1985 86 is estimated at 24 95 mln tonnes vs 24 95 mln last month canadian wheat exports in 1986 87 are forecast at 19 00 mln tonnes vs 18 00 mln tonnes last month exports in 1985 86 are estimated at 17 71 mln tonnes vs 17 72 mln last month reuter 3\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# turli xil lenga ega shuning uchun uni encoding qilish kerak\n",
        "import numpy as np\n",
        "\n",
        "def vectorized_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "\n",
        "\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    for j in sequences :\n",
        "      results[i, j] = 1.\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "geb43zQm1bUk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Endi data tayyor training qilish uchun\n",
        "x_train = vectorized_sequences(train_data)\n",
        "x_test = vectorized_sequences(test_data)"
      ],
      "metadata": {
        "id": "96B06LcO1qj0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#labellarni one hot orqali raqamli ko'rinishga o'tkazamiz\n",
        "import numpy as np\n",
        "\n",
        "def to_one_hot(labels, dimension = 46):\n",
        "  results = np.zeros((len(labels), dimension))\n",
        "\n",
        "  for i, label in enumerate (labels):\n",
        "    results[i, label] = 1.\n",
        "\n",
        "  return results\n",
        "\n",
        "\n",
        "y_train = to_one_hot(train_labels)\n",
        "y_test = to_one_hot(test_labels)"
      ],
      "metadata": {
        "id": "tAr9a-nG3GH1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bu funksiya label larni avtomatik ravishda one-hot encoded ko'rinishga o'tkazadi.\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(train_labels)\n",
        "y_test = to_categorical(test_labels)\n"
      ],
      "metadata": {
        "id": "MOczepPI7kby"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelni aniqlaymiz\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation = \"relu\"),\n",
        "    layers.Dense(64, activation = \"relu\"),\n",
        "    layers.Dense(46, activation = \"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "uCeoRkYS78Jh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFthQ56V8XSw",
        "outputId": "a9926554-3e54-46f4-8eb1-23753caecb2a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Sequential name=sequential_1, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#neyron tarmog'ini o'qitishga tayyorlash uchun kompilyatsiya qilamiz\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        " loss=\"categorical_crossentropy\",\n",
        " metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "s1xce7PHAMVv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trening va validation ma'lumotlariga ajratadi.\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "y_val = y_train[:1000]\n",
        "partial_y_train = y_train[1000:]"
      ],
      "metadata": {
        "id": "GydN8Wz9jdnA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelni train qilamiz\n",
        "history = model.fit(partial_x_train,\n",
        "partial_y_train,\n",
        "epochs=5,\n",
        "batch_size=512,\n",
        "validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU12IaJTjn8c",
        "outputId": "196bf9b1-f952-4f52-b8ec-ce57f4acf74e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.1647 - loss: 10.9360 - val_accuracy: 0.2220 - val_loss: 2.9605\n",
            "Epoch 2/5\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2259 - loss: 3.4210 - val_accuracy: 0.2220 - val_loss: 2.8800\n",
            "Epoch 3/5\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2966 - loss: 2.8179 - val_accuracy: 0.3540 - val_loss: 2.6272\n",
            "Epoch 4/5\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3589 - loss: 2.6205 - val_accuracy: 0.3540 - val_loss: 2.5133\n",
            "Epoch 5/5\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3488 - loss: 2.6040 - val_accuracy: 0.3540 - val_loss: 2.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelni aniqlaymiz\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")  # 46 classes for multi-class classification\n",
        "])\n",
        "\n",
        "#neyron tarmog'ini o'qitishga tayyorlash uchun kompilyatsiya qilamiz\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"categorical_crossentropy\",  # Use categorical crossentropy for multi-class\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Modelni train qilamiz\n",
        "model.fit(x_train, y_train, epochs=9, batch_size=512)\n",
        "\n",
        "# test data bo'yicha modelni baholaymiz\n",
        "results = model.evaluate(x_test, y_test)\n",
        "print(\"Test loss, Test accuracy:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY6gLQAEjpiT",
        "outputId": "649d7ff8-5a4e-4f82-d905-bb211abb70a2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.0853 - loss: 8.6041\n",
            "Epoch 2/9\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2545 - loss: 3.0390\n",
            "Epoch 3/9\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3293 - loss: 2.6348\n",
            "Epoch 4/9\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3492 - loss: 2.4794\n",
            "Epoch 5/9\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3006 - loss: 2.5656\n",
            "Epoch 6/9\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3548 - loss: 2.4817\n",
            "Epoch 7/9\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3176 - loss: 2.5353\n",
            "Epoch 8/9\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3287 - loss: 2.4855\n",
            "Epoch 9/9\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3473 - loss: 2.4331\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2116 - loss: 2.5402\n",
            "Test loss, Test accuracy: [2.5720221996307373, 0.21104185283184052]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import copy\n",
        ">>> test_labels_copy = copy.copy(test_labels)\n",
        ">>> np.random.shuffle(test_labels_copy)\n",
        ">>> hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
        ">>> hits_array.mean()\n",
        "0.18655387355298308"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvmmNulUjsNA",
        "outputId": "4f9b7b8c-4160-4b1e-99c3-670a402fd2f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18655387355298308"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression\n"
      ],
      "metadata": {
        "id": "hdkMa6nylllB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#boston_housing datani yuklab olamiz\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = (\n",
        " boston_housing.load_data())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7bvK0gYlihN",
        "outputId": "757e1fc5-fd8f-47d1-859b-72089948a436"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ1GjleAlijh",
        "outputId": "8d4a116b-395b-400b-8284-1bbff756f1a6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTkl8LUflil6",
        "outputId": "13ebeedb-c50f-4c81-c7fd-572ab437098e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data va test_data ma'lumotlarini normallashtirishtiradi\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "metadata": {
        "id": "wbkeJ6GYlioO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#neyron tarmog'i modelini yaratamiz\n",
        "def build_model():\n",
        " model = keras.Sequential([\n",
        " layers.Dense(64, activation=\"relu\"),\n",
        " layers.Dense(64, activation=\"relu\"),\n",
        " layers.Dense(1)\n",
        " ])\n",
        " model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        " return model"
      ],
      "metadata": {
        "id": "w0wrBb1Kliqk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 4  # foldlarning soni\n",
        "num_val_samples = len(train_data) // k  # Validation sample size per fold\n",
        "num_epochs = 100  # Number of epochs to train the model\n",
        "all_scores = []  # List to store scores (mean absolute error)\n",
        "\n",
        "for i in range(k):\n",
        "    print(f\"Processing fold #{i}\")\n",
        "\n",
        "    # validation va trening ma'lumotlariga bo'lamiz\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "  #kross-valldatsiya jarayonida har bir bo'lim uchun trening ma'lumotlarini tayyorlaymiz\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snNtSC3_lisZ",
        "outputId": "f4f8b16d-aa94-4fd4-9ff7-60af6a2a742d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing fold #0\n",
            "Processing fold #1\n",
            "Processing fold #2\n",
            "Processing fold #3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Modelni yaratish\n",
        "model = build_model()\n",
        "\n",
        "# Modelni o'qitish\n",
        "model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=16, verbose=0)\n",
        "\n",
        "# Modelni validatsiya ma'lumotlari bo'yicha baholash\n",
        "val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "\n",
        "# Validatsiya MAE ballini ro'yxatga qo'shish\n",
        "all_scores.append(val_mae)\n",
        "\n",
        "# Barcha ballarning o'rtacha qiymatini chop etish\n",
        "print(f\"Mean MAE: {np.mean(all_scores)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSSoLPfIcvzi",
        "outputId": "5221663e-89ed-4586-aa5b-43090dc05590"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MAE: 2.4502041339874268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#all_scores ro'yxatidagi qiymatlarning o'rtacha qiymatini hisoblamiz\n",
        "import numpy as np\n",
        "all_scores = [2.112449, 3.0801501, 2.6483836, 2.4275346]\n",
        "np.mean(all_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngMNd_-Olwc0",
        "outputId": "d7eac0a4-e98b-477a-b9f6-4c982c2dd7d5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.567129325"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "215EEp5glwe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NEC741o8lwhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jyoi6FR5lwjW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}